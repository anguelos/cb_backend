#!/usr/bin/env python3
import torch
import lm_util
from cb_unet import UNet, evaluate_binarization_improvement, render_confusion, get_otsu_threshold,render_optimal_confusion
from dagtasets import Dibco
import lm_util
import sys
import cv2
import time
from matplotlib import pyplot as plt

p={
    "log_freq":10,
    "lr":.001,
    "epochs":10,
    "device":"cuda",
    "val_device":"{device}",
    "validate_freq":5,
    "trainoutputs_freq":5,
    "batch_size":5,
    "save_freq":10,
    "lr":.001,
    "mask_gt":1,
    "resume_fname":"binnet_{mode}.pt",
    "mode":("normal",'One of ["normal","residual","chain","residual_chain"].')
}

p, _ = lm_util.get_arg_switches(p,sys.argv,return_named_tuple=True)

def save(per_epoch_train_errors,per_epoch_validation_errors,epoch,net):
    save_dict=net.state_dict()
    save_dict["per_epoch_train_errors"]=per_epoch_train_errors
    save_dict["per_epoch_validation_errors"] = per_epoch_validation_errors
    save_dict["epoch"]=epoch
    torch.save(save_dict, p.resume_fname)

def resume(net):
    try:
        save_dict=torch.load(p.resume_fname)
        per_epoch_train_errors=save_dict["per_epoch_train_errors"]
        del save_dict["per_epoch_train_errors"]
        per_epoch_validation_errors=save_dict["per_epoch_validation_errors"]
        del save_dict["per_epoch_validation_errors"]
        start_epoch=save_dict["epoch"]
        del save_dict["epoch"]
        net.load_state_dict(save_dict)
        print("Resumed from ",p.resume_fname)
        return per_epoch_train_errors,per_epoch_validation_errors,start_epoch,net
    except FileNotFoundError as e:
        print("Failed to resume from ", p.resume_fname)
        return {},{},0, net

def run_epoch(p,device,loader,net,criterion,optimizer=None,save_images=True):
    is_validation = optimizer is None
    net.to(device)
    if is_validation:
        isval_str = "Validation"
        do_grad=lambda: torch.no_grad()
        net.eval()
    else:
        do_grad = lambda: open("/tmp/fake","w")
        isval_str = "Train"
        net.train()
    fscores = []
    precisions = []
    recalls = []
    losses = []
    model_outputs={}
    t=time.time()
    with do_grad():
        for n, (input_img,gt,mask) in enumerate(loader):
            input_img, gt = input_img.to(device), gt.to(device)
            coeffs = gt[:,1,:,:].mean(dim=1).mean(dim=1)
            coeffs = coeffs.unsqueeze(dim=1).unsqueeze(dim=1).unsqueeze(dim=1)
            if p.mode == "normal":
                prediction = net(input_img)
                loss = criterion(prediction, gt)*coeffs
                prediction = torch.nn.functional.softmax(prediction, dim=1)
                prediction = torch.cat([prediction,1-prediction],dim=1).detach()

            elif p.mode == "residual":
                prediction = net(input_img) + torch.log(input_img)
                loss = criterion(prediction, gt)*coeffs
                prediction = torch.nn.functional.softmax(prediction, dim=1)
                prediction = torch.cat([prediction,1-prediction],dim=1).detach()

            elif p.mode == "chain":
                prediction = net(input_img)
                #loss = criterion(prediction, gt)*coeffs
                prediction = torch.nn.functional.softmax(prediction, dim=1)
                prediction = torch.cat([prediction[:,:1,:,:],1-prediction[:,:1,:,:]],dim=1)

                prediction = net(prediction)
                #loss = loss + criterion(prediction, gt).sum()*coeffs
                loss = criterion(prediction, gt) * coeffs
                prediction = torch.nn.functional.softmax(prediction, dim=1)
                prediction = torch.cat([prediction,1-prediction],dim=1).detach()

            elif p.mode == "residual_chain":
                prediction = net(input_img) + torch.log(input_img)
                #loss = criterion(prediction, gt)*coeffs
                prediction = torch.nn.functional.softmax(prediction, dim=1)
                prediction = torch.cat([prediction[:,:1,:,:],1-prediction[:,:1,:,:]],dim=1)

                prediction = net(prediction) + torch.log(prediction)
                #loss = loss + criterion(prediction, gt)*coeffs
                loss = criterion(prediction, gt) * coeffs

                prediction = torch.nn.functional.softmax(prediction, dim=1)
                prediction = torch.cat([prediction,1-prediction],dim=1).detach()
            else:
                raise ValueError("unknown mode")
            loss=loss.sum()
            if not is_validation:
                loss.backward()
                optimizer.step()
                optimizer.zero_grad()
            #bin_prediction = prediction[0,0,:,:]<get_otsu_threshold(prediction[0,0,:,:])
            #confusion,precision,recall,fscore = render_confusion(bin_prediction, gt[0, 0, :, :]<.5)
            confusion, precision, recall, fscore = render_confusion(prediction[0,0,:,:]<.5, gt[0, 0, :, :] < .5)
            #confusion,precision,recall,fscore = render_optimal_confusion(prediction[0,0,:,:], gt[0, 0, :, :]<.5)

            fscores.append(fscore)
            precisions.append(precision)
            recalls.append(recall)
            losses.append(loss.item()/gt.view(-1).size()[0])
            if save_images:
                cv2.imwrite("/tmp/{}_{}_img_{}.png".format(p.mode,isval_str,n), confusion)
                model_outputs[n]=prediction.detach().cpu()
    lines = ["{} {}:\t{}".format(isval_str[0],n,fscores[n]) for n in range(len(fscores))]
    lines.append("Epoch {} {} Total:\t{:05f}%".format(epoch, isval_str, 100*sum(fscores)/len(fscores)))
    lines.append('')
    print("N:\t{} {} % computed in {:05f} sec.".format(p.mode,isval_str,time.time()-t))
    print("\n".join(lines))
    if save_images:
        torch.save(model_outputs,"/tmp/{}_{}_samples.pt".format(p.mode,isval_str))
    return sum(fscores) / len(fscores),sum(precisions) / len(precisions), sum(recalls) / len(recalls),sum(losses) / len(losses)

device=torch.device(p.device)

trainset = Dibco(["2009_HW", "2009_P", "2010", "2011_P", "2011_HW", "2012", "2013", "2014", "2016", "2017"],train=True,mask_gt=p.mask_gt)
#trainset = Dibco(["2009_HW"])
testset = Dibco(["2018"], train=False)

trainloader=torch.utils.data.DataLoader(trainset, shuffle=True, batch_size=p.batch_size, num_workers= 8)
valloader=torch.utils.data.DataLoader(testset, shuffle=False, batch_size=1)

net = UNet(n_channels=2, n_classes=2)

per_epoch_train_errors,per_epoch_validation_errors,start_epoch,net=resume(net)

optim = torch.optim.Adam(net.parameters(), lr=p.lr)
criterion = torch.nn.BCEWithLogitsLoss(reduction='none')


for epoch in range(start_epoch, p.epochs):
    if p.save_freq != 0 and epoch % p.save_freq==0:
        save(per_epoch_train_errors,per_epoch_validation_errors,epoch,net)
    if p.validate_freq != 0 and epoch % p.validate_freq == 0:
        fscore,precision,recall,loss=run_epoch(p,p.val_device, valloader, net, criterion, optimizer=None, save_images=True)
        per_epoch_validation_errors[epoch]=fscore,precision,recall,loss
    save_outputs=p.trainoutputs_freq!=0 and epoch % p.trainoutputs_freq==0
    fscore, precision, recall, loss=run_epoch(p,p.device, trainloader, net, criterion, optimizer=optim, save_images=save_outputs)
    per_epoch_train_errors[epoch]=fscore, precision, recall, loss