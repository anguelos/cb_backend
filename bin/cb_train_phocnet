#!/usr/bin/env python3
import cbphocnet
import fargv
import torch
import numpy as np
import scipy.spatial.distance
import time
import tqdm
import glob

p = {
    "arch": "phocnet",
    "resume_path": "./models/{arch}_{fixed_size}.pt",
    "unigrams": "abcdefghijklmnopqrstuvwxyz0123456789",
    "pyramid_levels":[1, 2, 3, 4, 5],
    "input_channels": 1,
    "lr":.0001,
    "batch_size": 1,
    "fixed_size": "0x0",
    "optimizer": ("adam", "sgd"),
    "momentum": .9,
    "weight_decay": 0.00005,
    "loss":("bce", "cosine"),
    "batch_size": 10,
    "pseudo_batch_size": 1,
    "epochs": 100,
    "device": "cuda",
    "train_images": set(glob.glob("./data/fake_db/*/*jp2")),
    "train_gts": set(glob.glob("./data/fake_db/*/*gt.json")),
    "test_images": set(glob.glob("./data/fake_db/*/*jp2")),
    "test_gts": set(glob.glob("./data/fake_db/*/*gt.json")),
    "test_set_max_items": 3000,
    "validate_freq":1,
    "save_freq":1,
}


def evaluate_epoch(net, dataset, device, batch_size=1):
    net=net.to(device)
    net.train(False)
    sample_classes = np.empty(len(dataset), dtype=np.int)
    for n, (_, phoc) in enumerate(dataset):
        sample_classes[n] = (abs(hash(str(phoc))) % 1024 ** 3)
    class_map = {cl: n for n, cl in enumerate(np.sort(np.unique(sample_classes)).tolist())}
    sample_classes = np.array([class_map[n] for n in sample_classes.tolist()], dtype=np.int64)
    class_frequencies = np.bincount(sample_classes)
    non_unique_idx = class_frequencies[sample_classes] > 1
    dataloader = torch.utils.data.DataLoader(dataset, batch_size=batch_size, shuffle=False)
    outputs = []
    targets = []
    net = net.to(device)
    net.train(False)
    with torch.no_grad():
        for n, (word_image, embedding) in tqdm.tqdm(enumerate(dataloader), desc="Validating", leave=False):
            targets.append(embedding.numpy())
            word_image = word_image.to(device)
            outputs.append(torch.sigmoid(net(word_image)).cpu().numpy())
    outputs = np.concatenate(outputs, axis=0)
    targets = np.concatenate(targets, axis=0)
    dm = scipy.spatial.distance.cdist(outputs, targets, metric='cosine')
    idx = np.argsort(dm, axis=1)
    correct = sample_classes[idx] == sample_classes.reshape([-1, 1])
    correct = correct[:, 1:]
    correct = correct[non_unique_idx, :]
    accuracy = correct[:, 0].mean()
    return accuracy

def train_epoch(net, dataset, optimizer, criterium, device, batch_size, pseudo_batch_size):
    net=net.to(device)
    net.train(True)
    dataloader = torch.utils.data.DataLoader(dataset, shuffle=True, batch_size=batch_size)
    losses = []
    data_iter=tqdm.tqdm(enumerate(dataloader), leave=False,desc="Training")
    for n, (word_image, embedding) in data_iter:
        word_image, embedding = word_image.to(device), embedding.to(device)
        if n % pseudo_batch_size == 0:
            optimizer.zero_grad()
        output = net(word_image)
        loss = criterium(output, embedding).sum()
        loss.backward()
        if n % pseudo_batch_size == pseudo_batch_size-1:
            optimizer.step()
        losses.append(loss.detach().cpu().item())
        if n % 100 == 0:
            l=(sum(losses) / (1 + len(losses)))
            description = f"Training [Loss:{l:.8}]"
            data_iter.set_description(description, refresh=True)
    optimizer.step() # updating the last iterations
    return sum(losses)/len(losses)

def run_epoch(epoch, net, trainset, testset, optimizer, criterium, train_state, params):
    start_time = time.time()
    if epoch % params.validate_freq == 0:
        accuracy = evaluate_epoch(net, testset, params.device)
        print("acc.", accuracy)
    else:
        accuracy = train_state["accuracies"][-1] if train_state["accuracies"] else 0
    loss = train_epoch(net=net, dataset=trainset, optimizer=optimizer, criterium=criterium, device=params.device,batch_size=params.batch_size,pseudo_batch_size=params.pseudo_batch_size)
    train_state["accuracies"].append(accuracy)
    train_state["losses"].append(loss)
    train_state["batch_sizes"].append(params.batch_size)
    train_state["pseudo_batch_sizes"].append(params.pseudo_batch_size)
    train_state["parameters"] = vars(params)
    train_state["start_times"].append(start_time)
    train_state["end_times"].append(time.time())
    if epoch % params.save_freq == 0:
        net.save(params.resume_path, **train_state)
    return train_state


if __name__ == "__main__":
    p, _ = fargv.fargv(p)
    if p.fixed_size == "0x0":
        fixed_size = None
    else:
        fixed_size = tuple([int(v) for v in p.fixed_size.split("x")])

    if p.loss == "bce":
        criterium = torch.nn.BCEWithLogitsLoss(size_average=True)
    elif p.loss == "cosine":
        criterium = cbphocnet.CosineLoss(size_average=False, use_sigmoid=True)
    else:
        raise ValueError

    if p.arch == "phocnet":
        net = cbphocnet.PHOCNet(unigrams=p.unigrams, unigram_pyramids=p.pyramid_levels, input_channels=p.input_channels, fixed_size=fixed_size)
    else:
        raise NotImplementedError
    try:
        net, train_state = cbphocnet.PHOCNet.resume(p.resume_path, net=net)
    except:
        train_state = {"accuracies":[],"losses":[],"batch_sizes":[],"pseudo_batch_sizes":[],"start_times":[],
                       "end_times":[],"parameters":p}

    if p.optimizer == 'sgd':
        optimizer = torch.optim.SGD(net.parameters(), lr=p.lr, momentum=p.momentum, weight_decay=p.weight_decay)
    elif p.optimizer == 'adam':
        optimizer = torch.optim.Adam(net.parameters(), lr=p.lr, weight_decay=p.weight_decay)
    else:
        raise ValueError
    #trainset = cbphocnet.CBDataset(img_glob=p.img_glob, gt_glob=p.gt_glob, test_glob=p.testset_glob, train=True, net=net)
    #testset = cbphocnet.CBDataset(img_glob=p.img_glob, gt_glob=p.gt_glob, test_glob=p.testset_glob, train=False, net=net, keep_singletons=False, max_items=p.test_set_max_items)
    trainset = cbphocnet.CBDataset(img_paths=p.train_images, gt_paths=p.train_gts, train=True, net=net)
    testset = cbphocnet.CBDataset(img_paths=p.test_images, gt_paths=p.test_gts, train=False, net=net, keep_singletons=True, max_items=p.test_set_max_items)
    trange = tqdm.trange(p.epochs)
    for epoch in trange:
        train_state = run_epoch(epoch=epoch, net=net, trainset=trainset, testset=testset, optimizer=optimizer, criterium=criterium, train_state=train_state, params=p)
        description = f"Acc.:{train_state['accuracies'][-1]*100:.5}   Loss:{train_state['losses'][-1]:.7}"
        trange.set_description(description, refresh=True)
