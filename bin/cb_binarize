#!/usr/bin/env python3

from fargv import fargv
import sys
from cbbin import *

import time
import tqdm
import os

import torchvision

from PIL import Image, ImageFile
ImageFile.LOAD_TRUNCATED_IMAGES = True


#https://stackoverflow.com/questions/42462431/oserror-broken-data-stream-when-reading-image-file


p = {
    "n_channels": 1,
    "n_classes": 2,
    "io_threads": 0,
    "device": "cuda",
    "arch": [("srunet","dunet34","dunet18","dunet50","unet", "R2AttUNet", "AttUNet", "R2UNet", "UNet","runet","wrunet"),"Model Archtecture"],
    "cache_binary_postfix":".bin.png",
    "max_device_mp": 8.0,
    "resume_fname": "./models/{arch}.pt",
    "input":set([]),
}


input_transform = torchvision.transforms.Compose([torchvision.transforms.Grayscale(),torchvision.transforms.ToTensor()])

class InferenceDataset():
    def __init__(self, filename_list, transform=input_transform):
        self.filename_list = filename_list
        self.transform = transform

    def __getitem__(self, item):
        try:
            img = Image.open(self.filename_list[item])
        except IOError:
            print("Failed to load ", self.filename_list[item])
            img = Image.new('RGB', (1, 1))
        return self.transform(img), item

    def __len__(self):
        return len(self.filename_list)


def binarize_images(p, filenames=None):
    if filenames is None:
        filenames = p.input
    dataset = InferenceDataset(filenames)
    dataloader = torch.utils.data.DataLoader(dataset, shuffle=False, batch_size=1, num_workers=0)

    if p.arch == "otsu":
        net = create_net("otsu", 1, 2, .99, False, False)
    else:
        model_param_dict = sorted(torch.load(p.resume_fname, map_location="cpu")["param_hist"].items())[-1][1]
        net = create_net(model_param_dict["arch"], model_param_dict["n_channels"], model_param_dict["n_classes"], .99,
                         False, False)
    _, _, _, _, net = resume(net, p.resume_fname, p.device)
    net = net.eval().to("cuda")

    total_t = time.time()
    with torch.no_grad():
        for image, n in dataloader:
            n = n.item()
            binary_out_fname = dataset.filename_list[n] + p.cache_binary_postfix
            try:
                out_gray = torchvision.transforms.ToTensor()(Image.open(binary_out_fname))
                print(f"{n} Loading cached {binary_out_fname}")
            except IOError:
                image_t = time.time()
                patches = 0
                if image.size(2)*image.size(3) > p.max_device_mp*(1000**2):
                    output = torch.zeros([1,2,image.size(2), image.size(3)])
                    width = height = int((p.max_device_mp ** .5) * 1000)
                    #print("Computing patches:")
                    for left in range(0, image.size(3), width//2):
                        right = min([left+width,image.size(3)])
                        for top in range(0, image.size(2), height//2):
                            bottom = min([top + height, image.size(2)])
                            output[:, :, top:bottom, left:right] = net(image[:, :, top:bottom, left:right].to(p.device))
                            patches += 1
                            #print(f"{n}:[{left:6},{right:6},{top:6},{bottom:6}]")
                    #        print(".",end="")
                    #    print("")
                else:
                    patches = 1
                    image = image.to(p.device)
                    output = net(image)
                print(f"{n} [{image.size(3)}x{image.size(2)}] Pixels: {patches} patches in {time.time()-image_t:.5} sec. total:{time.time()-total_t:.2} sec.{binary_out_fname}")
                out_gray = torch.softmax(output,dim=1)[0,0,:,:]
                torchvision.transforms.ToPILImage()(out_gray).save(binary_out_fname)
            yield out_gray, dataset.filename_list[n], n


#PYTHONPATH="./:./thirdparty/iunets" ./bin/cb_binarize -max_device_mp 1. -input ./data/annotated/blovice/soap-pj_00485_mesto-blovice-1837-1954_0*jp2 ./data/annotated/hroznetin/soap-kv_00240_obec-hroznetin-1949-1954_0*jp2

if __name__ == "__main__":
    param_dict, _ = fargv(p.copy(), argv=sys.argv.copy(), return_named_tuple=False)
    p, _ = fargv(p, return_named_tuple=True)
    device = torch.device(p.device)
    filenames = [f for f in p.input if not os.path.isfile(f+p.cache_binary_postfix)]
    print(f"Given files:{len(p.input)}, uncached:{len(filenames)}")
    for _ in binarize_images(p, filenames=filenames):
        pass
