#!/usr/bin/env python3

import torch
from fargv import fargv
import sys
import PIL
import cbsegm
import cbbin
from cbbin import *
from matplotlib import pyplot as plt
import time
import tqdm

import torchvision

from PIL import Image, ImageFile
ImageFile.LOAD_TRUNCATED_IMAGES = True
#https://stackoverflow.com/questions/42462431/oserror-broken-data-stream-when-reading-image-file


p = {
    "binary_images": set([]),
    "annotations": set([]),
    "boxle_path": "/tmp/boxle.json"
}


#PYTHONPATH="./:./thirdparty/iunets" ./bin/cb_train_component_classifier -binary_images ./data/annotated/chudenice/*bin.png -annotations ./data/annotated/chudenice/*.json

if __name__ == "__main__":
    param_dict, _ = fargv(p.copy(), argv=sys.argv.copy(), return_named_tuple=False)
    p, _ = fargv(p, return_named_tuple=True)
    assert len(p.binary_images) == len(p.annotations)
    id_to_binimg = {f.split("/")[-1].split(".")[0]: f for f in p.binary_images}
    id_to_annotations = {f.split("/")[-1].split(".")[0]: f for f in p.annotations}
    features = []
    for id in id_to_binimg.keys():
        prob_img = np.array(PIL.Image.open(id_to_binimg[id]))
        boxes, words = cbsegm.load_annotator_json_words(id_to_annotations[id])
        features.append(cbsegm.extract_bbox_features(boxes, prob_img))
    features = np.concatenate(features, axis=0)
    estimator = cbsegm.BoxLikelihoodEstimator()
    estimator.train(features)
    estimator.save(p.boxle_path)
