#!/usr/bin/env python3

import torch
from fargv import fargv
import sys
import PIL
import pickle
import cbbin
from cbbin import *
from matplotlib import pyplot as plt
import time
import tqdm

import torchvision

from PIL import Image, ImageFile
ImageFile.LOAD_TRUNCATED_IMAGES = True
import cbsegm

#https://stackoverflow.com/questions/42462431/oserror-broken-data-stream-when-reading-image-file


p = {
    "prob_images":set([]),
    "target_postfix":".words.pickle",
    "target_prefix":"",
    "boxle_path": "/tmp/boxle.json",
    "rlsa_distances": "[0,4,8, 16]",
    "thresholds":"[128]",
    "nms_threshold":.95
}

# PYTHONPATH="./:./thirdparty/iunets" ./bin/cb_propose_words -prob_images ./data/annotated/*/*bin.png -target_postfix .words.json

if __name__ == "__main__":
    param_dict, _ = fargv(p.copy(), argv=sys.argv.copy(), return_named_tuple=False)
    p, _ = fargv(p, return_named_tuple=True)
    box_likelihood_estimator = cbsegm.BoxLikelihoodEstimator.load(p.boxle_path)
    thresholds = eval(p.thresholds)
    rlsa_distances = eval(p.rlsa_distances)
    for img_name in p.prob_images:
        id = img_name[img_name.rfind("/"):].split(".")[0]
        if p.target_prefix=="":
            target_root=img_name[:img_name.rfind("/")]
        else:
            target_root=p.target_prefix

        target_path=f"{target_root}/{id}{p.target_postfix}"
        prob_img = PIL.Image.open(img_name)
        #prob_img.show()
        prob_img = np.array(prob_img)
        print("prob_img:", np.unique(prob_img))
        proposals = cbsegm.word_proposals(prob_img, box_likelihood_estimator, thresholds=thresholds, rlsa_gaps=rlsa_distances, iou_threshold=p.nms_threshold)
        if p.target_postfix.endswith("pickle"):
            with open(target_path, "wb") as fd:
                pickle.dump(proposals, fd)
        elif p.target_postfix.endswith("json"):
            cbsegm.save_annotator_json_words(target_path,proposals)
        else:
            raise NotImplementedError()
