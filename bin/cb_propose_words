#!/usr/bin/env python3

import torch
from fargv import fargv
import sys
import PIL
import pickle
import cbbin
from cbbin import *
from matplotlib import pyplot as plt
import time
import tqdm

import torchvision

from PIL import Image, ImageFile
ImageFile.LOAD_TRUNCATED_IMAGES = True
import cbsegm

#https://stackoverflow.com/questions/42462431/oserror-broken-data-stream-when-reading-image-file


p = {
    "prob_images":set([]),
    "target_postfix": ".words.pickle",
    "target_prefix": "",
    "box_model": "/tmp/box_iou.pt",
    "rlsa_distances": "[0,2,4,6,12,18,24]",
    "thresholds": "[32, 64, 128, 224]",
    "nms_threshold": .6,
    "min_word_length": 8,
    "min_word_height": 6,
    "max_word_length": .2,
    "max_word_height": .1,
    "threads": 1,
    "device": "cuda"
}

# PYTHONPATH="./:./thirdparty/iunets" ./bin/cb_propose_words -prob_images ./data/annotated/*/*bin.png -target_postfix .words.json


if __name__ == "__main__":
    param_dict, _ = fargv(p.copy(), argv=sys.argv.copy(), return_named_tuple=False)
    p, _ = fargv(p, return_named_tuple=True)
    try:
        net = cbsegm.BoxIOUPredictor()
        net.load_state_dict(torch.load(p.box_model, map_location='cpu')["state"])
        net.train(False)
        net = net.to(p.device)
        box_predictor = lambda x: torch.exp(net(torch.tensor(x,dtype=torch.float,device=p.device))[:,1]).detach().cpu().numpy()
    except FileNotFoundError:
        box_predictor = lambda x: np.random.rand(x.shape[0])
    thresholds = eval(p.thresholds)
    rlsa_distances = eval(p.rlsa_distances)
    for img_name in tqdm.tqdm(p.prob_images):
        id = img_name[img_name.rfind("/"):].split(".")[0]
        if p.target_prefix=="":
            target_root=img_name[:img_name.rfind("/")]
        else:
            target_root=p.target_prefix
        target_path=f"{target_root}/{id}{p.target_postfix}"
        prob_img = PIL.Image.open(img_name)
        prob_img = np.array(prob_img)
        proposals = cbsegm.word_proposals(prob_img, box_predictor, thresholds=thresholds, rlsa_gaps=rlsa_distances,
                                          iou_threshold=p.nms_threshold,
                                          min_word_legth=p.min_word_length,
                                          min_word_height=p.min_word_height,
                                          max_word_length=p.max_word_length,
                                          max_word_height=p.max_word_height)
        if p.target_postfix.endswith("pickle"):
            with open(target_path, "wb") as fd:
                pickle.dump(proposals, fd)
        elif p.target_postfix.endswith("json"):
            cbsegm.save_annotator_json_words(target_path,proposals)
        else:
            raise NotImplementedError()
